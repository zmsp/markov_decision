# MARKOV decision making 

notebook/markov_experiments.ipynb file contains all the experiments.

# Quick Start
1. On a python environment run pip3 install -r requirements.txt
2. Run jupter notebook from the notebook directory
3. Profit


## About
I will come up with two interesting MDPs and explain why they are interesting. The first MDP will have a small number of states and the second MDP will have a large number of states. I will solve each MDP using value iteration and policy iteration. I will choose to define convergence as the point where the value of the MDP converges to within a certain threshold. I expect that the MDP with a large number of states will take more iterations to converge than the MDP with a small number of states. I also expect that the MDP with a large number of states will converge to the same answer as the MDP with a small number of states. I will pick my favorite reinforcement learning algorithm and use it to solve the two MDPs. I will compare the performance of the reinforcement learning algorithm to the cases where I knew the model, rewards, and so on. I will choose to use an exploration strategy that is known to work well.
Steps taken: 

1. Choose two interesting MDPs.
2. Solve each MDP using value iteration as well as policy iteration.
3. Choose your favorite reinforcement learning algorithm and use it to solve the two MDPs.

